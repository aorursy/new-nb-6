# This Python 3 environment comes with many helpful analytics libraries installed

# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python

# For example, here's several helpful packages to load in 



import numpy as np # linear algebra

import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)



# Input data files are available in the "../input/" directory.

# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory



import os

print(os.listdir("../input"))



import matplotlib

import matplotlib.pyplot as plt



import seaborn as sns






import time





# due to Kaggle memory limitations and the enormous dataset size, a sample from the whole

# trainset will be used for ML modeling

train_sample_fraction = 0.2





# another global variable that must be defined is the NA values rate / theshold to ommit columns with

# NA values that pass this rate

na_rate_threshold = 0.9



# theshold to remove columns with unbalanced features to their values 

unbalanced_feature_rate_threshold = 0.9



# Any results you write to the current directory are saved as output.
# I am grateful for the help of author of this kernel for the main idea to load the dataset and save memory space!!

# https://www.kaggle.com/theoviel/load-the-totality-of-the-data



dtypes = {

        'MachineIdentifier':                                    'category',

        'ProductName':                                          'category',

        'EngineVersion':                                        'category',

        'AppVersion':                                           'category',

        'AvSigVersion':                                         'category',

        'IsBeta':                                               'int8',

        'RtpStateBitfield':                                     'float16',

        'IsSxsPassiveMode':                                     'int8',

        'DefaultBrowsersIdentifier':                            'float16',

        'AVProductStatesIdentifier':                            'float32',

        'AVProductsInstalled':                                  'float16',

        'AVProductsEnabled':                                    'float16',

        'HasTpm':                                               'int8',

        'CountryIdentifier':                                    'int16',

        'CityIdentifier':                                       'float32',

        'OrganizationIdentifier':                               'float16',

        'GeoNameIdentifier':                                    'float16',

        'LocaleEnglishNameIdentifier':                          'int8',

        'Platform':                                             'category',

        'Processor':                                            'category',

        'OsVer':                                                'category',

        'OsBuild':                                              'int16',

        'OsSuite':                                              'int16',

        'OsPlatformSubRelease':                                 'category',

        'OsBuildLab':                                           'category',

        'SkuEdition':                                           'category',

        'IsProtected':                                          'float16',

        'AutoSampleOptIn':                                      'int8',

        'PuaMode':                                              'category',

        'SMode':                                                'float16',

        'IeVerIdentifier':                                      'float16',

        'SmartScreen':                                          'category',

        'Firewall':                                             'float16',

        'UacLuaenable':                                         'float32',

        'Census_MDC2FormFactor':                                'category',

        'Census_DeviceFamily':                                  'category',

        'Census_OEMNameIdentifier':                             'float16',

        'Census_OEMModelIdentifier':                            'float32',

        'Census_ProcessorCoreCount':                            'float16',

        'Census_ProcessorManufacturerIdentifier':               'float16',

        'Census_ProcessorModelIdentifier':                      'float16',

        'Census_ProcessorClass':                                'category',

        'Census_PrimaryDiskTotalCapacity':                      'float32',

        'Census_PrimaryDiskTypeName':                           'category',

        'Census_SystemVolumeTotalCapacity':                     'float32',

        'Census_HasOpticalDiskDrive':                           'int8',

        'Census_TotalPhysicalRAM':                              'float32',

        'Census_ChassisTypeName':                               'category',

        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',

        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',

        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',

        'Census_PowerPlatformRoleName':                         'category',

        'Census_InternalBatteryType':                           'category',

        'Census_InternalBatteryNumberOfCharges':                'float32',

        'Census_OSVersion':                                     'category',

        'Census_OSArchitecture':                                'category',

        'Census_OSBranch':                                      'category',

        'Census_OSBuildNumber':                                 'int16',

        'Census_OSBuildRevision':                               'int32',

        'Census_OSEdition':                                     'category',

        'Census_OSSkuName':                                     'category',

        'Census_OSInstallTypeName':                             'category',

        'Census_OSInstallLanguageIdentifier':                   'float16',

        'Census_OSUILocaleIdentifier':                          'int16',

        'Census_OSWUAutoUpdateOptionsName':                     'category',

        'Census_IsPortableOperatingSystem':                     'int8',

        'Census_GenuineStateName':                              'category',

        'Census_ActivationChannel':                             'category',

        'Census_IsFlightingInternal':                           'float16',

        'Census_IsFlightsDisabled':                             'float16',

        'Census_FlightRing':                                    'category',

        'Census_ThresholdOptIn':                                'float16',

        'Census_FirmwareManufacturerIdentifier':                'float16',

        'Census_FirmwareVersionIdentifier':                     'float32',

        'Census_IsSecureBootEnabled':                           'int8',

        'Census_IsWIMBootEnabled':                              'float16',

        'Census_IsVirtualDevice':                               'float16',

        'Census_IsTouchEnabled':                                'int8',

        'Census_IsPenCapable':                                  'int8',

        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',

        'Wdft_IsGamer':                                         'float16',

        'Wdft_RegionIdentifier':                                'float16',

        'HasDetections':                                        'int8'

        }



def reduce_mem_usage(df, verbose=True):

    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']

    start_mem = df.memory_usage(deep=True).sum() / 1024**2    

    for col in df.columns:

        col_type = df[col].dtypes

        if col_type in numerics:

            c_min = df[col].min()

            c_max = df[col].max()

            if str(col_type)[:3] == 'int':

                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:

                    df[col] = df[col].astype(np.int8)

                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:

                    df[col] = df[col].astype(np.int16)

                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:

                    df[col] = df[col].astype(np.int32)

                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:

                    df[col] = df[col].astype(np.int64)  

            else:

                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:

                    df[col] = df[col].astype(np.float16)

                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:

                    df[col] = df[col].astype(np.float32)

                else:

                    df[col] = df[col].astype(np.float64)    

    end_mem = df.memory_usage(deep=True).sum() / 1024**2

    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))

    return df

train = pd.read_csv('../input/train.csv', dtype=dtypes)
good_cols = list(train.columns)



for col in train.columns:

    

    # remove columns with high NA rate

    na_rate = train[col].isnull().sum() / train.shape[0]

    

    # remove columns with high Unbalanced values rate

    unbalanced_rate = train[col].value_counts(normalize=True, dropna=False).values[0]

    

    if na_rate > na_rate_threshold:

        good_cols.remove(col)

    elif unbalanced_rate > unbalanced_feature_rate_threshold:

        good_cols.remove(col)
good_cols
train = train[good_cols]
import gc



gc.collect()
categorical_columns = list(train.loc[:, train.dtypes =="category"].columns)

numerical_and_binary_columns = list(train.loc[:, train.dtypes !="category"].columns)

numerical_columns = numerical_and_binary_columns



categorical_columns.remove("MachineIdentifier")



binary_columns = []

for col in (numerical_and_binary_columns):

    if train[col].nunique() == 2:

        binary_columns.append(col)

        numerical_columns.remove(col)
train_sample = train.sample(frac=train_sample_fraction, random_state=42)

del train

gc.collect()
train_sample.shape
test_dtypes = {k: v for k, v in dtypes.items() if k in good_cols}



# get all columns except

test = pd.read_csv('../input/test.csv', dtype=test_dtypes, usecols=good_cols[:-1])



#test = reduce_mem_usage(test)
test.head()
test.shape
train_sample = train_sample.drop(['MachineIdentifier'], axis=1)

test = test.drop(['MachineIdentifier'], axis=1)
train_sample = train_sample.reset_index(drop=True)
modes = train_sample.mode()



for col in train_sample.columns:

    train_sample[col] = np.where(train_sample[col].isnull(), modes[col], train_sample[col])



del modes
modes_test = test.mode()



for col in test.columns:

    test[col] = np.where(test[col].isnull(), modes_test[col], test[col])



#train_sample.shape

del modes_test
train_shape = train_sample.shape

test_shape = test.shape



train_and_test = pd.concat([train_sample,test], axis="rows", sort=False)



del train_sample

del test

gc.collect()
train_and_test.head()
train_and_test.tail()
from sklearn.preprocessing import LabelEncoder

from sklearn.preprocessing import OneHotEncoder



def MultiLabelEncoder(columnlist,dataframe):

    for i in columnlist:

        #print(i)

        labelencoder_X=LabelEncoder()

        dataframe[i]=labelencoder_X.fit_transform(dataframe[i])



MultiLabelEncoder(categorical_columns, train_and_test)
gc.collect()
train_sample = train_and_test[0:train_shape[0]]

test = train_and_test[(train_shape[0]):(train_and_test.shape[0]+1)]
del train_and_test
test = test.drop(["HasDetections"], axis = 1)
y = train_sample['HasDetections']

X = train_sample.drop(['HasDetections'], axis=1)
del train_sample

gc.collect()
# main idea:

# https://www.kaggle.com/infinitewing/k-fold-cv-xgboost-example-0-28?scriptVersionId=1553202



from sklearn.model_selection import train_test_split

from sklearn.model_selection import KFold

import xgboost as xgb

from sklearn.metrics import accuracy_score

from sklearn.metrics import precision_score

from sklearn.metrics import recall_score

from sklearn.metrics import f1_score

from sklearn.metrics import classification_report

from sklearn.metrics import roc_auc_score

from sklearn import metrics

import time

import random



K = 5

index = 0

predictions_proba_test_list = np.zeros(len(test))

fold_auc_list = []

fold_accuracy_list = []



kf = KFold(n_splits = K, random_state = 42, shuffle = True)



for train_index, test_index in kf.split(X):

    

    print("Fold:", index)

    index = index + 1

    

    train_X, valid_X = X.iloc[train_index, :], X.iloc[test_index, :]

    train_y, valid_y = y[train_index], y[test_index]

    

    new_seed =  random.randint(1, 2000)

    

    clf_xgb = xgb.XGBClassifier(learning_rate=0.03, 

                            n_estimators=1300, 

                            max_depth=8,

                            min_child_weight=4,

                            gamma=0,

                            subsample=0.8,

                            colsample_bytree=0.7,

                            objective= 'binary:logistic',

                            nthread=-1,

                            scale_pos_weight=1,

                            reg_alpha = 0.1,

                            reg_lambda = 1,

                            seed=new_seed)



    clf_xgb.fit(train_X, train_y, eval_set=[(train_X, train_y), (valid_X, valid_y)], 

            early_stopping_rounds=100, eval_metric='auc', verbose=100)

    

    temp_predictions_proba_test_list = []



    # read test set in chunks

    chunck = 400000

    test_times = test.shape[0] // chunck

    test_rest = test.shape[0] % chunck



    for i in  np.arange(0,(chunck * (test_times+1)), chunck):

        

        # create predictions in chunks due ot memory limitations

        predictions_proba_test = list(clf_xgb.predict_proba(test[i:(i+chunck)])[:,1])

        temp_predictions_proba_test_list.append(predictions_proba_test)

        #print("times:", i)





    # flatten the list of lists

    temp_predictions_proba_test_list = [y for x in temp_predictions_proba_test_list for y in x]

    

    

    #print(np.shape(predictions_proba_test_list))

    predictions_proba_test_list = [sum(x) for x in zip(predictions_proba_test_list, temp_predictions_proba_test_list)]

    #print(test.shape)

    #print(np.shape(predictions_proba_test_list))



    

    predictions = clf_xgb.predict(valid_X, ntree_limit=clf_xgb.n_estimators)



    print()

    print(classification_report(valid_y, predictions))



    print()

    print("accuracy_score", accuracy_score(valid_y, predictions))

    

    predictions_probas = clf_xgb.predict_proba(valid_X)[:,1]

    print("auc score", roc_auc_score(valid_y, predictions_probas))

    print()

    

    fold_accuracy_list.append(accuracy_score(valid_y, predictions))

    fold_auc_list.append(roc_auc_score(valid_y, predictions_probas))



print()

print("Mean auc:", np.mean(fold_auc_list))

print("Std auc:", np.std(fold_auc_list))



print("Mean accuracy:", np.mean(fold_accuracy_list))

print("Std accuracy:", np.std(fold_accuracy_list))



gc.collect()
predictions_proba_test_list = [x / kf.n_splits for x in predictions_proba_test_list]
from sklearn.metrics import confusion_matrix

import scikitplot as skplt



sns.set(rc={'figure.figsize':(8,8)})

skplt.metrics.plot_confusion_matrix(valid_y, predictions, cmap="BrBG")
sns.set(rc={'figure.figsize':(8,8)})

predictions_probas = clf_xgb.predict_proba(valid_X)

skplt.metrics.plot_roc(valid_y, predictions_probas)
sns.set(rc={'figure.figsize':(8,8)})

skplt.metrics.plot_ks_statistic(valid_y, predictions_probas)
sns.set(rc={'figure.figsize':(8,8)})

skplt.metrics.plot_precision_recall(valid_y, predictions_probas)
# I may implement tuning in the future but I am afraid of variance - bias tradeoff

'''

#idea and a big thank you to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/

from sklearn.model_selection import GridSearchCV   #Perforing grid search



gc.collect()



param_test1 = {

    # based on previous personal kernels both parameters show better result having high numbers 

 'max_depth':[3, 5, 7, 9, 11],

 'min_child_weight':[1, 3, 5, 7, 9]

}

gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.05, n_estimators=70, gamma=0, subsample=0.8, colsample_bytree=0.8,

                                                  objective= 'binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha = 0, 

                                                reg_lambda =1, seed=42), 

                        param_grid = param_test1, scoring='roc_auc', n_jobs=1, iid=False, cv=3, verbose = 1)



gsearch1.fit(xtrain, ytrain)

gsearch1.best_params_, gsearch1.best_score_

'''
del X

del y

del train_X

del train_y

del valid_X

del valid_y

del predictions

del predictions_probas

del temp_predictions_proba_test_list

del clf_xgb

gc.collect()
submission = pd.read_csv('../input/sample_submission.csv')

submission['HasDetections'] = predictions_proba_test_list

submission.to_csv('xgboost.csv', index=False)