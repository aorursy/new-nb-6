import warnings

warnings.filterwarnings("ignore", category=DeprecationWarning)

warnings.filterwarnings("ignore", category=UserWarning)

warnings.filterwarnings("ignore", category=FutureWarning)

from IPython.display import HTML
import pdb

import cv2

import pandas as pd

import numpy as np

from PIL import Image

from pathlib import Path

from matplotlib import pyplot as plt

from mpl_toolkits.mplot3d import axes3d, Axes3D



# Load the SDK

from lyft_dataset_sdk.lyftdataset import LyftDataset, LyftDatasetExplorer, Quaternion, view_points

from lyft_dataset_sdk.utils.data_classes import LidarPointCloud



from moviepy.editor import ImageSequenceClip

from tqdm import tqdm_notebook as tqdm



# gotta do this for LyftDataset SDK, it expects folders to be named as `images`, `maps`, `lidar`






lyftdata = LyftDataset(data_path='.', json_path='data/', verbose=True)
lyftdata.category[0]
cat_token = lyftdata.category[0]['token']

cat_token
lyftdata.get('category', cat_token)
lyftdata.sample_annotation[0]
lyftdata.get('attribute', lyftdata.sample_annotation[0]['attribute_tokens'][0])
lyftdata.scene[0]
train = pd.read_csv('../input/3d-object-detection-for-autonomous-vehicles/train.csv')

train.head()
token0 = train.iloc[0]['Id']

token0
my_sample = lyftdata.get('sample', token0)

my_sample
lyftdata.render_sample_3d_interactive(my_sample['token'], render_sample=False)
my_sample.keys()
lyftdata.sensor
sensor = 'CAM_FRONT'

cam_front = lyftdata.get('sample_data', my_sample['data'][sensor])

cam_front
img = Image.open(cam_front['filename'])

img
lyftdata.render_sample_data(cam_front['token'], with_anns=False)
lidar_top = lyftdata.get('sample_data', my_sample['data']['LIDAR_TOP']) # selecting LIDAR_TOP out of all LIDARs

lidar_top
pc = LidarPointCloud.from_file(Path(lidar_top['filename']))
pc.points.shape # x, y, z, intensity
axes_limits = [

    [-30, 50], # X axis range

    [-30, 20], # Y axis range

    [-3, 10]   # Z axis range

]

axes_str = ['X', 'Y', 'Z']



def display_frame_statistics(lidar_points, points=0.2):

    """

    Displays statistics for a single frame. Draws 3D plot of the lidar point cloud data and point cloud

    projections to various planes.

    

    Parameters

    ----------

    lidar_points: lidar data points 

    points          : Fraction of lidar points to use. Defaults to `0.2`, e.g. 20%.

    """

    

    points_step = int(1. / points)

    point_size = 0.01 * (1. / points)

    pc_range = range(0, lidar_points.shape[1], points_step)

    pc_frame = lidar_points[:, pc_range]

    def draw_point_cloud(ax, title, axes=[0, 1, 2]):

        """Convenient method for drawing various point cloud projections as a part of frame statistics"""

        ax.set_facecolor('black')

        ax.grid(False)

        ax.scatter(*pc_frame[axes, :], s=point_size, c='white', cmap='grey')

        if len(axes) == 3: # 3D configs

            text_color = 'white'

            ax.set_xlim3d([-10, 30])

            ax.set_ylim3d(*axes_limits[axes[1]])

            ax.set_zlim3d(*axes_limits[axes[2]])

            ax.set_zlabel('{} axis'.format(axes_str[axes[2]]), color='white')

        else: # 2D configs

            text_color = 'black' # the `figure` is white

            ax.set_xlim(*axes_limits[axes[0]])

            ax.set_ylim(*axes_limits[axes[1]])

        ax.set_title(title, color=text_color)

        ax.set_xlabel('{} axis'.format(axes_str[axes[0]]), color=text_color)

        ax.set_ylabel('{} axis'.format(axes_str[axes[1]]), color=text_color)

            

    # Draw point cloud data as 3D plot

    f2 = plt.figure(figsize=(15, 8))

    ax2 = f2.add_subplot(111, projection='3d')

    # make the panes transparent

    ax2.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))

    ax2.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))

    ax2.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))

    draw_point_cloud(ax2, '3D plot')

    

    plt.show()

    plt.close(f2)

    # Draw point cloud data as plane projections

    f, ax3 = plt.subplots(3, 1, figsize=(15, 25))

#     f.set_facecolor('black')

    draw_point_cloud(

        ax3[0], 

        'XZ projection (Y = 0)', #, the car is moving in direction left to right', ?

        axes=[0, 2] # X and Z axes

    )

    draw_point_cloud(

        ax3[1], 

        'XY projection (Z = 0)', #, the car is moving in direction left to right',? 

        axes=[0, 1] # X and Y axes

    )

    draw_point_cloud(

        ax3[2], 

        'YZ projection (X = 0)', #, the car is moving towards the graph plane', ?

        axes=[1, 2] # Y and Z axes

    )

    plt.show()

    plt.close(f)
display_frame_statistics(pc.points, points=0.5)
lyftdata.render_sample_data(lidar_top['token'], with_anns=False)
lyftdata.get('ego_pose', cam_front['ego_pose_token'])
lyftdata.get('calibrated_sensor', cam_front['calibrated_sensor_token'])
my_annotation = lyftdata.get('sample_annotation', my_sample['anns'][0])

my_annotation
my_box = lyftdata.get_box(my_annotation['token'])

my_box # Box class instance
my_box.center, my_box.wlh # center coordinates + width, length and height
lyftdata.render_annotation(my_annotation['token'], margin=10)
my_attribute1 = lyftdata.get('attribute', my_annotation['attribute_tokens'][0])

my_attribute2 = lyftdata.get('attribute', my_annotation['attribute_tokens'][1])
my_attribute1
my_attribute2
my_instance = lyftdata.get('instance', my_annotation['instance_token'])

my_instance
lyftdata.render_instance(my_instance['token'])
print("First annotated sample of this instance:")

lyftdata.render_annotation(my_instance['first_annotation_token'])
print("Last annotated sample of this instance")

lyftdata.render_annotation(my_instance['last_annotation_token'])
lyftdata.render_sample(token0)
my_scene = lyftdata.get('scene',  my_sample['scene_token'])
def get_lidar_points(lidar_token):

    '''Get lidar point cloud in the frame of the ego vehicle'''

    sd_record = lyftdata.get("sample_data", lidar_token)

    sensor_modality = sd_record["sensor_modality"]

    

    # Get aggregated point cloud in lidar frame.

    sample_rec = lyftdata.get("sample", sd_record["sample_token"])

    chan = sd_record["channel"]

    ref_chan = "LIDAR_TOP"

    pc, times = LidarPointCloud.from_file_multisweep(

        lyftdata, sample_rec, chan, ref_chan, num_sweeps=1

    )

    # Compute transformation matrices for lidar point cloud

    cs_record = lyftdata.get("calibrated_sensor", sd_record["calibrated_sensor_token"])

    pose_record = lyftdata.get("ego_pose", sd_record["ego_pose_token"])

    vehicle_from_sensor = np.eye(4)

    vehicle_from_sensor[:3, :3] = Quaternion(cs_record["rotation"]).rotation_matrix

    vehicle_from_sensor[:3, 3] = cs_record["translation"]

    

    ego_yaw = Quaternion(pose_record["rotation"]).yaw_pitch_roll[0]

    rot_vehicle_flat_from_vehicle = np.dot(

        Quaternion(scalar=np.cos(ego_yaw / 2), vector=[0, 0, np.sin(ego_yaw / 2)]).rotation_matrix,

        Quaternion(pose_record["rotation"]).inverse.rotation_matrix,

    )

    vehicle_flat_from_vehicle = np.eye(4)

    vehicle_flat_from_vehicle[:3, :3] = rot_vehicle_flat_from_vehicle

    points = view_points(

        pc.points[:3, :], np.dot(vehicle_flat_from_vehicle, vehicle_from_sensor), normalize=False

    )

    return points
def plot_box(box, axis, view, colors, normalize=False, linewidth=1.0):

    '''Plot boxes in the 3d figure'''

    corners = view_points(box.corners(), view, normalize=normalize)#

    def draw_rect(selected_corners, color):

        prev = selected_corners[-1]

        for corner in selected_corners:

            axis.plot([prev[0], corner[0]], [prev[1], corner[1]], [prev[2], corner[2]], color=color, linewidth=linewidth)

            prev = corner



    # Draw the sides

    for i in range(4):

        axis.plot(

            [corners.T[i][0], corners.T[i + 4][0]],

            [corners.T[i][1], corners.T[i + 4][1]],

            [corners.T[i][2], corners.T[i + 4][2]],

            color=colors[2],

            linewidth=linewidth,

        )



    # Draw front (first 4 corners) and rear (last 4 corners) rectangles(3d)/lines(2d)

    draw_rect(corners.T[:4], colors[0]) #4x3

    draw_rect(corners.T[4:], colors[1])
def draw_3d_plot(idx, lidar_token):

    '''Plot the lidar + annotations on a 3D figure'''

    # sample lidar point cloud

    lidar_points = get_lidar_points(lidar_token)

    points = 0.5 # fraction of lidar_points to plot, to reduce the clutter

    points_step = int(1. / points)

    pc_range = range(0, lidar_points.shape[1], points_step)

    lidar_points = lidar_points[:, pc_range]

    

    # Get boxes, instead of current sensor's coordinate frame, use vehicle frame which is aligned to z-plane in world

    _, boxes, _ = lyftdata.get_sample_data(

        lidar_token, flat_vehicle_coordinates=True

    )

    fig = plt.figure(figsize=(15, 8))

    ax = fig.add_subplot(111, projection='3d')                    

    point_size = 0.01 * (1. / points) # size of the dots on plot

    ax.set_facecolor('black')

    ax.grid(False)

    ax.scatter(*lidar_points, s=point_size, c='white', cmap='gray')

    for box in boxes:

        c = np.array(lyftdata.explorer.get_color(box.name)) / 255.0

        plot_box(box, ax, view=np.eye(3), colors=(c, c, c), linewidth=0.5)

    ax.set_xlim3d(-40, 40)

    ax.set_ylim3d(-40, 40)

    ax.set_zlim3d(-4, 40)

    

    # make the panes transparent

    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))

    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))

    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))

    ax.set_title(lidar_token, color='white')

    filename = 'tmp/frame_{0:0>4}.png'.format(idx)

    plt.savefig(filename)

    plt.close(fig)

    return filename
# let's take a quick look at the 3d Plot

first_sample_token = my_scene['first_sample_token']

sample = lyftdata.get('sample', first_sample_token)

lidar_token = sample['data']['LIDAR_TOP']

filename = draw_3d_plot(0, lidar_token)

Image.open(filename)
frames = []

first_sample_token = my_scene['first_sample_token']

token = first_sample_token

for i in tqdm(range(my_scene['nbr_samples'])):

    sample = lyftdata.get('sample', token)

    lidar_token = sample['data']['LIDAR_TOP']

    filename = draw_3d_plot(i, lidar_token)

    frames += [filename]

    token = sample['next']

#     break
clip = ImageSequenceClip(frames, fps=5)

clip.write_gif('pcl_data.gif', fps=5);
from IPython.core.interactiveshell import InteractiveShell

InteractiveShell.ast_node_interactivity = "all"

from IPython import display
with open('pcl_data.gif','rb') as f:

    display.Image(data=f.read(), format='png')
# The rendering command below is commented out because it tends to crash in notebooks,

# lyftdata.render_scene(my_scene['token'])
HTML('<iframe width="700" height="500" src="https://www.youtube.com/embed/Vs8H8Fs-zTs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>')
HTML('<iframe width="700" height="430" src="https://www.youtube.com/embed/ivmiN4zvRTo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>')